{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "WatermarkRemoval-CGAN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gUwO8Z4jpG7"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms, models\n",
        "from torch import optim\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "import os\n",
        "import pickle\n",
        "import matplotlib.pyplot as plt\n",
        "import random \n",
        "import glob"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vV4qWnSQLg-R",
        "outputId": "8f71d74a-67de-4f2e-cad9-daad43e85b7a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zWJBhM1V8GFa"
      },
      "source": [
        "%%bash\n",
        "rm -rf images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzoY1ZF14ahs"
      },
      "source": [
        "%%bash\n",
        "mkdir images\n",
        "wget -O images/Dataset.zip https://github.com/jbrownlee/Datasets/releases/download/Flickr8k/Flickr8k_Dataset.zip \n",
        "mkdir images/dataset\n",
        "unzip -d images/Dataset/ images/Dataset.zip\n",
        "ls -v images/Dataset/Flicker8k_Dataset/ | cat -n | while read n f; do mv -n \"images/Dataset/Flicker8k_Dataset/$f\" \"images/dataset/$n.jpg\"; done\n",
        "wget -O images/wm.png https://drive.google.com/uc?id=1FqvgBV3ZMsRgsxbyTbJtzhwwD2f6wW2A&export=download\n",
        "mkdir images/watermarked\n",
        "mkdir images/original\n",
        "mkdir images/test\n",
        "mkdir images/output\n",
        "rm -rf images/Dataset\n",
        "rm -rf images/Dataset.zip\n",
        "mkdir saved_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1lM3hMIv4m7s"
      },
      "source": [
        "def gen_watermark(dataset_path, watermark_img_path, output_path, samples, og_img_path=None, test=False):\n",
        "  # Read the original image + dimension\n",
        "  og_img = glob.glob(dataset_path)\n",
        "\n",
        "  print('Adding watermarks')\n",
        "\n",
        "  images = og_img[:samples]\n",
        "\n",
        "  if test:\n",
        "    images = og_img[-samples:]\n",
        "\n",
        "  for i in og_img[:samples]:\n",
        "      img = Image.open(i)\n",
        "      img_w, img_h = img.size\n",
        "\n",
        "      if og_img_path:\n",
        "        filename = os.path.basename(i)\n",
        "        # Save resized original image\n",
        "        img.save(og_img_path + filename)\n",
        "\n",
        "      # Read the watermark image + dimension\n",
        "      watermark = Image.open(watermark_img_path)\n",
        "\n",
        "      WM_SIZE = random.choice([1.1, 1.2, 1.3])\n",
        "      # Resize the watermark in proportion to original image\n",
        "      basewidth = int(img_w // WM_SIZE)\n",
        "      wpercent = (basewidth / float(watermark.size[0]))\n",
        "      hsize = int((float(watermark.size[1]) * float(wpercent)))\n",
        "      watermark = watermark.resize((basewidth, hsize), Image.ANTIALIAS)\n",
        "\n",
        "      # If watermark image is not a PNG\n",
        "      if watermark.mode!='RGBA':\n",
        "          alpha = Image.new('L', watermark.size, 255)\n",
        "          watermark.putalpha(alpha)\n",
        "\n",
        "      watermark_w, watermark_h = watermark.size\n",
        "\n",
        "      # Randomly select transparency\n",
        "      TRANSPARENCY = random.randint(40, 100)\n",
        "\n",
        "      # Randomly assign watermark coordinates\n",
        "      water_w, water_h = (random.randint(0, img_w - watermark_w), random.randint(0, img_h - watermark_h))\n",
        "      paste_mask = watermark.split()[3].point(lambda i: i * TRANSPARENCY / 100.)\n",
        "      img.paste(watermark, (water_w, water_h), mask=paste_mask)\n",
        "\n",
        "      filename = os.path.basename(i)\n",
        "      # Save watermarked image\n",
        "      img.save(output_path + filename)\n",
        "\n",
        "  print('Watermark added to all the images')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11eKywTMAPjK"
      },
      "source": [
        "%%bash\n",
        "rm -rf images/watermarked/*\n",
        "rm -rf images/original/*\n",
        "rm -rf images/test/*"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZ9JMTSc47VH",
        "outputId": "cb49c94e-b90f-4bdb-9a02-71526f8e24d6"
      },
      "source": [
        "dataset_path = 'images/dataset/*.*'\n",
        "watermark_img_path = 'images/wm.png'\n",
        "watermarked_img_path = 'images/watermarked/'\n",
        "test_path = 'images/test/'\n",
        "og_img_path = 'images/original/'\n",
        "gen_path = 'images/output/'\n",
        "train_samples = 100\n",
        "test_samples = 20\n",
        "\n",
        "# Generate watermarked training set\n",
        "print(\"=== Train set ===\")\n",
        "gen_watermark(dataset_path, watermark_img_path, watermarked_img_path, train_samples, og_img_path, test=False)\n",
        "\n",
        "# Generate watermarked test set\n",
        "print(\"\\n\\n=== Test set ===\")\n",
        "gen_watermark(dataset_path, watermark_img_path, test_path, test_samples, test=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "=== Train set ===\n",
            "Adding watermarks\n",
            "Watermark added to all the images\n",
            "\n",
            "\n",
            "=== Test set ===\n",
            "Adding watermarks\n",
            "Watermark added to all the images\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MoCKu24_3w-Q"
      },
      "source": [
        "def conv(in_ch, out_ch, kernel_size=4, stride=2, padding=1, instance_norm=True):\n",
        "    layers = []\n",
        "    conv_layer = nn.Conv2d(in_ch, out_ch, kernel_size, stride, padding, bias=False)\n",
        "    layers.append(conv_layer)\n",
        "\n",
        "    if instance_norm:\n",
        "      layers.append(nn.InstanceNorm2d(out_ch))\n",
        "\n",
        "    return nn.Sequential(*layers)\n",
        "\n",
        "# upsampling -> convolution -> InstanceNorm (optional)\n",
        "def upsampling(in_ch, out_ch, kernel_size=3, stride=1, padding=1, instance_norm=True):\n",
        "    layers=[]\n",
        "    upsample=nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
        "    layers.append(upsample)\n",
        "    conv_layer = nn.Conv2d(in_ch, out_ch, kernel_size, stride, padding, bias=False)\n",
        "    layers.append(conv_layer)\n",
        "\n",
        "    if instance_norm:\n",
        "      layers.append(nn.InstanceNorm2d(out_ch))\n",
        "\n",
        "    return nn.Sequential(*layers)    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qXnKJMCj3w-S"
      },
      "source": [
        "# Architecture based on https://arxiv.org/pdf/1905.12845.pdf\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, conv_dim=64):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.conv_dim = conv_dim\n",
        "        self.conv1 = conv(6, conv_dim)                                # 6->64    w/2 h/2\n",
        "        self.conv2 = conv(conv_dim, conv_dim*2, instance_norm=False)  # 64->128  w/4 h/4\n",
        "        self.conv3 = conv(conv_dim*2, conv_dim*4, 3, 1, 1, False)     # 128->256 w/4 h/4\n",
        "        self.norm1 = nn.InstanceNorm2d(conv_dim*2)\n",
        "        self.norm2 = nn.InstanceNorm2d(conv_dim*4)\n",
        "        # Final fully-connected layer\n",
        "        self.conv4 = conv(conv_dim*4, 1, 3, 1, 1, False)\n",
        "        self.norm3 = nn.InstanceNorm2d(1)\n",
        "\n",
        "    def forward(self, xx):\n",
        "        # Hidden layers + leaky relu activation\n",
        "        out = self.conv1(xx)\n",
        "        out = F.leaky_relu(self.conv2(out), 0.2)\n",
        "        out = self.norm1(out)\n",
        "        out = F.leaky_relu(self.conv3(out), 0.2)\n",
        "        out = self.norm2(out)\n",
        "        out = self.conv4(out)\n",
        "        out = self.norm3(out)\n",
        "        out = torch.sigmoid(out)\n",
        "        \n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RVeD6zW3w-T"
      },
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, conv_dim=64):\n",
        "        super(Generator, self).__init__()\n",
        "        self.conv_dim = conv_dim\n",
        "        self.norm1=nn.InstanceNorm2d(3)\n",
        "        self.conv1=conv(3, conv_dim , instance_norm=False)              # 3->64       w/2 h/2\n",
        "        self.conv2 = conv(conv_dim, conv_dim*2, instance_norm=True)     # 64->128     w/4 h/4\n",
        "        self.conv3 = conv(conv_dim*2, conv_dim*4, instance_norm=True)   # 128->256    w/8 h/8\n",
        "        self.conv4 = conv(conv_dim*4, conv_dim*4, instance_norm=False)  # 256->256    w/16 h/16\n",
        "        \n",
        "        self.upsample1=upsampling(conv_dim*4, conv_dim*4) # upsampling -> conv2d-> Instance norm    256->256  w/8 h/8\n",
        "        # First skip connection  256->512  w/8 h/8\n",
        "        self.upsample2=upsampling(conv_dim*8, conv_dim*2) # upsampling -> conv2d-> Instance norm    512->128  w/4 h/4\n",
        "        # Second skip connection 128->256  w/4 h/4\n",
        "        self.upsample3=upsampling(conv_dim*4, conv_dim)   # upsampling -> conv2d-> Instance norm    256->64   w/2 h/2\n",
        "        # Third skip connection  64->128   w/2 h/2\n",
        "        self.upsample4=upsampling(conv_dim*2, 3, instance_norm=False) # upsampling -> conv2d        128->3    w   h \n",
        "\n",
        "    def forward(self, xx):\n",
        "        out=self.norm1(xx)\n",
        "        out=self.conv1(out)\n",
        "        out=F.leaky_relu(out, 0.2)\n",
        "        res1=out  # Store result for skip connection\n",
        "        out1=self.conv2(out)\n",
        "\n",
        "        res2=out1 \n",
        "        out2=F.leaky_relu(out1, 0.2)\n",
        "        out2=self.conv3(out2)\n",
        "\n",
        "        res3=out2\n",
        "        out3=F.leaky_relu(out2, 0.2)\n",
        "        out3=self.conv4(out3)\n",
        "\n",
        "        out3=F.relu(out3)\n",
        "\n",
        "        out3=self.upsample1(out3)\n",
        "        out3=torch.cat((res3, out3), 1)\n",
        "        out3=F.relu(out3)\n",
        "\n",
        "        out3=self.upsample2(out3)\n",
        "        out3=torch.cat((res2, out3), 1)\n",
        "        out3=F.relu(out3)\n",
        "\n",
        "        out3=self.upsample3(out3)\n",
        "        out3=torch.cat((res1, out3), 1)\n",
        "        out3=F.relu(out3)\n",
        "\n",
        "        out3=self.upsample4(out3)\n",
        "\n",
        "        return out3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UA0mxWbIoiNh"
      },
      "source": [
        "### Loss functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3uRuSob3w-T"
      },
      "source": [
        "alpha = 10\n",
        "beta = 1e-4\n",
        "\n",
        "# Use pretrained VGG-16 feature extractor for generator\n",
        "vgg = models.vgg16(pretrained=True).features\n",
        "if torch.cuda.is_available():\n",
        "  vgg = vgg.cuda()\n",
        "\n",
        "def L1_loss(og_img, pred_img):\n",
        "    L1_loss = torch.sum(torch.abs((pred_img - og_img)))/(pred_img.size()[1]*pred_img.size()[2]*pred_img.size()[3])\n",
        "    return L1_loss\n",
        "\n",
        "def perceptual_loss(og_img, pred_img, model):\n",
        "    for name, layer in model._modules.items():\n",
        "        og_img = layer(og_img)\n",
        "        pred_img = layer(pred_img)\n",
        "        if(name == \"8\"):  # Layer 8 is relu2_2\n",
        "            break\n",
        "    p_loss = torch.sum(torch.pow((pred_img - og_img), 2))/(og_img.size()[1]*og_img.size()[2]*og_img.size()[3])\n",
        "    return p_loss\n",
        "\n",
        "# Define generator loss\n",
        "def G_loss(og_img, pred_img, watermark_img, D, G, model):\n",
        "    p1 = D(torch.cat((watermark_img,pred_img),1))\n",
        "    G_loss = -torch.log(torch.mean(p1))+alpha*L1_loss(og_img, pred_img)+beta*perceptual_loss(og_img, pred_img, model)\n",
        "    return G_loss\n",
        "\n",
        "# Define discriminator loss\n",
        "def D_loss(og_img, pred_img, watermark_img, D, G):\n",
        "    p0 = D(torch.cat((watermark_img, og_img),1))\n",
        "    p1 = D(torch.cat((watermark_img, pred_img),1))\n",
        "    D_loss = - (torch.log(torch.mean(p0)) + torch.log(1.-torch.mean(p1)))\n",
        "    return D_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VONPfFD3w-U"
      },
      "source": [
        "lr = 1e-4\n",
        "beta1 = 0.5\n",
        "beta2 = 0.999\n",
        "\n",
        "# Create new models for training\n",
        "G=Generator()\n",
        "D=Discriminator()\n",
        "\n",
        "# If using saved model, uncomment lines below\n",
        "# G=torch.load(\"saved_model/g749_model.pkl\")\n",
        "# D=torch.load(\"saved_model/d749_model.pkl\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    G = G.cuda()\n",
        "    D = D.cuda()\n",
        "\n",
        "d_optimizer = optim.Adam(D.parameters(), lr, [beta1, beta2])\n",
        "g_optimizer = optim.Adam(G.parameters(), lr, [beta1, beta2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnVYSLb13w-U"
      },
      "source": [
        "def show_img(original_img,watermarked_img,pred_img):\n",
        "    print(\"Original image\")\n",
        "    plt.imshow(np.transpose(original_img.cpu().numpy().reshape(3,(int)(w-w%16),(int)(h-h%16)),[2,1,0]))\n",
        "    plt.show()\n",
        "\n",
        "    print(\"Watermarked image\")\n",
        "    plt.imshow(np.transpose(watermarked_img.cpu().numpy().reshape(3,(int)(w-w%16),(int)(h-h%16)),[2,1,0]))\n",
        "    plt.show()\n",
        "\n",
        "    print(\"Generated image\")\n",
        "    pred_img=(pred_img-pred_img.min())/(pred_img.max()-pred_img.min())\n",
        "    plt.savefig(gen_path)\n",
        "    plt.imshow(np.transpose(pred_img.cpu().detach().numpy().reshape(3,(int)(w-w%16),(int)(h-h%16)),[2,1,0]))\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4338LDnWj5l"
      },
      "source": [
        "def get_tensor(img, h, w):\n",
        "  img = cv2.resize(img, ((int)(w-w%16), (int)(h-h%16)), interpolation = cv2.INTER_CUBIC)\n",
        "  img = np.transpose(img, (2, 1, 0))\n",
        "  img = img.reshape(1, 3, (int)(w-w%16), (int)(h-h%16))\n",
        "  img = img/255\n",
        "  img_tensor = torch.tensor(img, dtype=torch.float32)\n",
        "\n",
        "  return img_tensor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m8kq7OIxo48O"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohffVQA-3w-V"
      },
      "source": [
        "epoch = 500\n",
        "count = 0\n",
        "\n",
        "for i in range(epoch):\n",
        "    for name in os.listdir(watermarked_img_path):\n",
        "\n",
        "        no_watermark_img=np.array(Image.open(og_img_path+\"/\"+name))\n",
        "        h = no_watermark_img.shape[0]\n",
        "        w = no_watermark_img.shape[1]\n",
        "        no_watermark_img = get_tensor(no_watermark_img, h, w)\n",
        "\n",
        "        watermark_img=np.array(Image.open(watermarked_img_path+\"/\"+name))\n",
        "        h = watermark_img.shape[0]\n",
        "        w = watermark_img.shape[1]\n",
        "        watermark_img = get_tensor(watermark_img, h, w)\n",
        "    \n",
        "        if torch.cuda.is_available():\n",
        "            no_watermark_img = no_watermark_img.cuda()\n",
        "            watermark_img = watermark_img.cuda()\n",
        "\n",
        "        # Train generator \n",
        "        g_optimizer.zero_grad()\n",
        "        pred_img = G(watermark_img)\n",
        "        pred_img = (pred_img-pred_img.min())/(pred_img.max()-pred_img.min())\n",
        "        g_loss = G_loss(no_watermark_img, pred_img, watermark_img, D, G, vgg)\n",
        "        g_loss.backward()\n",
        "        g_optimizer.step()\n",
        "\n",
        "        # Train discriminator\n",
        "        d_optimizer.zero_grad()\n",
        "        pred_img = G(watermark_img)\n",
        "        pred_img = (pred_img-pred_img.min())/(pred_img.max()-pred_img.min())\n",
        "        d_loss = D_loss(no_watermark_img, pred_img, watermark_img, D, G)\n",
        "        d_loss.backward()\n",
        "        d_optimizer.step()\n",
        "\n",
        "        if(count%500 == 0):\n",
        "          print('Train Epoch: {:3} \\t D Loss: {:F} \\t G Loss: {:F}'.format(\n",
        "            i, d_loss.item(), g_loss.item()))\n",
        "        \n",
        "        if(count%501 == 0):\n",
        "            show_img(no_watermark_img,watermark_img,pred_img)\n",
        "        \n",
        "        count += 1\n",
        "  \n",
        "    # Save model periodically \n",
        "    if((i+1)%250 == 0):\n",
        "        torch.save(D, 'saved_model/d{}_model.pkl'.format(i+250))  \n",
        "        torch.save(G, 'saved_model/g{}_model.pkl'.format(i+250))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ObysGEReQ8Hm"
      },
      "source": [
        "### Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QPFeZ4FxQ6Te"
      },
      "source": [
        "def get_img(img, w, h):\n",
        "    img = np.transpose(img, (2, 1, 0))\n",
        "    img = img.reshape(1, 3, (w-w%16), (h-h%16))\n",
        "    img = img/255\n",
        "    img = torch.tensor(img,dtype=torch.float32)\n",
        "    \n",
        "    if torch.cuda.is_available():\n",
        "        img=img.cuda()\n",
        "\n",
        "    img = G(img)\n",
        "    img = (img-img.min())/(img.max()-img.min())\n",
        "    \n",
        "    return img\n",
        "\n",
        "def test(G, path):\n",
        "    print(\"Test image\")\n",
        "    img = np.array(Image.open(path))\n",
        "    h = img.shape[0]\n",
        "    w =i mg.shape[1]\n",
        "    img = cv2.resize(img, ((int)(w-w%16), (int)(h-h%16)), interpolation = cv2.INTER_CUBIC)\n",
        "\n",
        "    plt.imshow(img)\n",
        "    plt.show()\n",
        "\n",
        "    print(\"Generated image\")\n",
        "    img = get_img(img, w, h)\n",
        "    plt.imshow(np.transpose(img.cpu().detach().numpy().reshape(3,(w-w%16), (h-h%16)), [2,1,0]))\n",
        "    plt.show()\n",
        "\n",
        "for i in range(test_samples):\n",
        "    test(G, test_path + \"/\" + os.listdir(test_path)[i])"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}